{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75d9cd85-e357-433a-81ee-19972831c9b9",
   "metadata": {},
   "source": [
    "# Kalman Filter in Autonomous Driving Systems\n",
    "\n",
    "The **Kalman filter** is a recursive algorithm used to estimate the state of a dynamic system from noisy or incomplete observations. In autonomous driving, it is commonly used to track objects such as vehicles, pedestrians, or cyclists over time, even when they temporarily disappear or sensor readings are noisy.\n",
    "\n",
    "### Overview of Kalman Filter in ADS Context\n",
    "\n",
    "The Kalman filter provides a **best estimate** of the object's state at each time step by combining:\n",
    "1. The **current observation** from sensors (which may be noisy or incomplete).\n",
    "2. The **previous state** estimate and a prediction of how the object is expected to move (based on a motion model).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. State Vector (Response)\n",
    "\n",
    "The **state vector** represents the dynamic properties of the object that we want to estimate and track. For example, in 2D tracking, the state vector might include:\n",
    "- **Position (x, y)**: The 2D coordinates of the object in the vehicle’s local reference frame.\n",
    "- **Velocity (v_x, v_y)**: The speed of the object in the x and y directions.\n",
    "\n",
    "At time step $ t $, the state vector could look like:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_t = \\begin{bmatrix} x_t \\\\ y_t \\\\ v_{x_t} \\\\ v_{y_t} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Observation Vector (Features)\n",
    "\n",
    "The **observation vector** contains the actual measurements from the sensors, which may only include the position, for example:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_t = \\begin{bmatrix} \\hat{x}_t \\\\ \\hat{y}_t \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $ \\hat{x}_t $ and $ \\hat{y}_t $ are the measured (observed) positions.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. State Transition Model (Evolving Model)\n",
    "\n",
    "The **state transition model** predicts how the object's state evolves from one time step to the next. A simple linear motion model assuming constant velocity is:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = \\mathbf{A} \\mathbf{x}_t + \\mathbf{B} \\mathbf{u}_t + \\mathbf{w}_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mathbf{A} $ is the **state transition matrix**.\n",
    "- $ \\mathbf{B} $ is the control input matrix (optional, often zero in simple cases).\n",
    "- $ \\mathbf{w}_t $ is the process noise (modeled as Gaussian).\n",
    "\n",
    "For a **constant velocity model**, the state transition matrix might be:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix} \n",
    "1 & 0 & \\Delta t & 0 \\\\\n",
    "0 & 1 & 0 & \\Delta t \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $ \\Delta t $ is the time step.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Observation Model\n",
    "\n",
    "The **observation model** maps the true state of the object to the measurements:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_t = \\mathbf{H} \\mathbf{x}_t + \\mathbf{v}_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mathbf{H} $ is the **observation matrix**.\n",
    "- $ \\mathbf{v}_t $ is the measurement noise (Gaussian).\n",
    "\n",
    "For example, if we only observe position, the observation matrix $ \\mathbf{H} $ would be:\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Gaussian Noise (Uncertainty Models)\n",
    "\n",
    "Both the **process noise** $ \\mathbf{w}_t $ and **measurement noise** $ \\mathbf{v}_t $ are modeled as zero-mean Gaussian distributions:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_t \\sim \\mathcal{N}(0, \\mathbf{Q})\n",
    "$$\n",
    "$$\n",
    "\\mathbf{v}_t \\sim \\mathcal{N}(0, \\mathbf{R})\n",
    "$$\n",
    "\n",
    "Where $ \\mathbf{Q} $ and $ \\mathbf{R} $ are the process and measurement noise covariance matrices, respectively.\n",
    "\n",
    "---\n",
    "\n",
    "## Kalman Filter Equations\n",
    "\n",
    "The Kalman filter operates in two steps: **prediction** and **update**.\n",
    "\n",
    "### **Prediction Step**\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_{t+1|t} = \\mathbf{A} \\hat{\\mathbf{x}}_t\n",
    "$$\n",
    "$$\n",
    "\\mathbf{P}_{t+1|t} = \\mathbf{A} \\mathbf{P}_t \\mathbf{A}^T + \\mathbf{Q}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\hat{\\mathbf{x}}_{t+1|t} $ is the predicted state.\n",
    "- $ \\mathbf{P}_{t+1|t} $ is the predicted covariance matrix (uncertainty).\n",
    "\n",
    "### **Update Step**\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_{t+1} = \\mathbf{z}_{t+1} - \\mathbf{H} \\hat{\\mathbf{x}}_{t+1|t}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{S}_{t+1} = \\mathbf{H} \\mathbf{P}_{t+1|t} \\mathbf{H}^T + \\mathbf{R}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{K}_{t+1} = \\mathbf{P}_{t+1|t} \\mathbf{H}^T \\mathbf{S}_{t+1}^{-1}\n",
    "$$\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_{t+1} = \\hat{\\mathbf{x}}_{t+1|t} + \\mathbf{K}_{t+1} \\mathbf{y}_{t+1}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{P}_{t+1} = (\\mathbf{I} - \\mathbf{K}_{t+1} \\mathbf{H}) \\mathbf{P}_{t+1|t}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mathbf{y}_{t+1} $ is the **measurement residual**.\n",
    "- $ \\mathbf{K}_{t+1} $ is the **Kalman gain**, balancing the prediction with the new observation.\n",
    "\n",
    "---\n",
    "\n",
    "## Kalman Filter in Object Tracking (ADS Example)\n",
    "\n",
    "In an ADS scenario, the Kalman filter helps to smooth out noisy sensor data and predicts the object’s next state (e.g., car, pedestrian). For example:\n",
    "- If a car is temporarily occluded, the filter predicts its future position.\n",
    "- If sensors detect different numbers of objects, the filter can estimate the likely position of missing objects based on prior estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "The Kalman filter is a probabilistic framework for estimating an object's position and velocity by fusing noisy sensor measurements and applying a prediction model. In autonomous driving, it is used for object tracking, even when sensor data is noisy or incomplete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec842cb-18f1-4fbb-9295-f6d754cfc46b",
   "metadata": {},
   "source": [
    "# Real-Time Object Tracking and Occlusion Handling in Autonomous Driving\n",
    "\n",
    "In autonomous driving systems, **data association** and **object tracking** algorithms are used in real-time to handle situations where objects (e.g., pedestrians, vehicles) become temporarily occluded, such as when a pedestrian disappears behind a bus. Algorithms like the **Kalman filter** (or its variants) are commonly employed to predict the object’s location during occlusion and maintain safe driving behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## Real-Time Object Tracking for Occlusion Handling\n",
    "\n",
    "Autonomous driving systems rely on real-time tracking models to predict the future positions of objects when sensor data becomes unavailable due to occlusion or noise. These models include:\n",
    "\n",
    "### 1. **Tracking Models in Real-Time**\n",
    "Models like the **Kalman filter**, **Extended Kalman filter (EKF)**, or more advanced algorithms like **particle filters** and **multi-hypothesis tracking (MHT)** are used to handle occlusions.\n",
    "\n",
    "For example, when a pedestrian disappears behind a bus, the Kalman filter:\n",
    "- Uses the **last known state** of the pedestrian (position, velocity) to predict where they are likely to be.\n",
    "- Continues **updating the state estimate** as long as the pedestrian remains occluded, providing a probabilistic estimate of their location.\n",
    "- **Corrects the prediction** when the pedestrian reappears by updating the state with new sensor measurements.\n",
    "\n",
    "In real-time, this allows the vehicle to predict and track the occluded pedestrian, ensuring it can take cautious actions like slowing down or preparing to stop.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Handling Occlusions with Real-Time Predictions**\n",
    "When objects are temporarily invisible to sensors, the system continues to predict their likely future position using models like the Kalman filter.\n",
    "\n",
    "**Example**: \n",
    "- A pedestrian crosses a street and is occluded by a bus.\n",
    "  - The system **predicts** the pedestrian's movement using a constant velocity model (Kalman filter).\n",
    "  - The system **updates the prediction** frame-by-frame, expecting the pedestrian to reappear at the predicted location.\n",
    "  - The vehicle may **slow down** or **prepare to stop** based on the predicted location of the pedestrian.\n",
    "\n",
    "Even though the object is occluded, the system treats the predicted state as **high priority**, maintaining safety precautions.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Advanced Models for Complex Occlusions**\n",
    "For more complex tracking scenarios, such as handling multiple occluded objects or erratic movements, advanced models like **multi-object tracking (MOT)** or **multi-hypothesis tracking (MHT)** are employed.\n",
    "\n",
    "- **Multi-Hypothesis Tracking (MHT)**: Keeps multiple hypotheses about the location of occluded objects, evaluating them as more data comes in.\n",
    "- **Particle Filters**: Represent the state of an object as a distribution of possible states (particles). This is useful when future movements are uncertain, such as for erratic pedestrian motion.\n",
    "\n",
    "These models handle more complex situations where multiple objects may reappear in different locations after occlusion.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Real-Time Performance Considerations**\n",
    "Real-time tracking models are designed for efficiency:\n",
    "- **Low-latency algorithms**: Kalman filters, particle filters, and MHT are optimized to run quickly, ensuring predictions are made in real-time.\n",
    "- **Parallel processing**: Tracking systems are often implemented using parallel computing to process sensor data from LiDAR, radar, and cameras simultaneously.\n",
    "- **Sensor fusion**: Autonomous systems combine data from different sensors to improve tracking accuracy. If one sensor (e.g., camera) is occluded, other sensors (e.g., LiDAR) can still provide data.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Post-Occlusion Re-identification**\n",
    "When objects reappear after occlusion, the system must **re-identify** them and continue tracking. This involves:\n",
    "- **Comparing the predicted state** (from the Kalman filter) with the detected state after reappearance.\n",
    "- **Resolving ambiguities** if multiple objects reappear after occlusion.\n",
    "\n",
    "**Example**:\n",
    "- A pedestrian reappears from behind a bus.\n",
    "  - The system compares their position with the **predicted position**.\n",
    "  - If matched, tracking resumes.\n",
    "\n",
    "If the system doesn’t detect the object at the predicted location, it may take further precautions, such as stopping the vehicle.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Flow of Handling Pedestrian Occlusion in Real-Time\n",
    "\n",
    "1. **Pre-Occlusion**: \n",
    "   - The system detects a pedestrian crossing the street at a certain velocity.\n",
    "   - The pedestrian moves behind a bus.\n",
    "\n",
    "2. **During Occlusion**:\n",
    "   - The tracking system uses the **Kalman filter** to predict the pedestrian’s future position.\n",
    "   - The system anticipates where the pedestrian will reappear and adjusts vehicle behavior (e.g., slowing down).\n",
    "\n",
    "3. **Post-Occlusion**:\n",
    "   - The pedestrian reappears, and the system compares the **predicted** and **actual** positions.\n",
    "   - If they match, tracking resumes.\n",
    "\n",
    "4. **Uncertainty**:\n",
    "   - If the pedestrian doesn’t reappear, the system takes a more cautious approach, potentially stopping.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "Yes, models like the **Kalman filter**, **particle filters**, and **multi-hypothesis tracking** are used in **real-time** in autonomous driving systems to handle occlusion scenarios. These models predict the positions of occluded objects based on prior motion, allowing the system to continue tracking objects even when they are temporarily invisible. \n",
    "\n",
    "Handling occlusions effectively is crucial for the safety and reliability of autonomous vehicles, especially in complex environments like urban areas where occlusions are frequent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33f79e-3161-45de-b145-a81b2e949761",
   "metadata": {},
   "source": [
    "## Beyond single path like Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47c12e-ebcb-4731-b16a-330e7768cd8e",
   "metadata": {},
   "source": [
    "\n",
    "- MHT: State-of-the-art MHT approaches like DeepSORT, JPDAF, and GNN-based models are widely used in multi-object tracking for autonomous driving systems, especially in handling occlusions and ambiguous object detections.\n",
    "\n",
    "- Particle Filters: These are a class of Sequential Monte Carlo (SMC) methods used to handle non-linear and non-Gaussian tracking problems. The proposal distribution in particle filters can be learned from historical data, allowing for the generation of more accurate future paths for occluded objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076dc4f-4c1d-4519-b02b-35bfb52dfbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
